---
permalink: /
title: "Chenchen Jing (景宸琛)"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- This is the front page of a website that is powered by the [academicpages template](https://github.com/academicpages/academicpages.github.io) and hosted on GitHub pages. [GitHub pages](https://pages.github.com) is a free service in which websites are built and hosted from code and data stored in a GitHub repository, automatically updating when a new commit is made to the respository. This template was forked from the [Minimal Mistakes Jekyll Theme](https://mmistakes.github.io/minimal-mistakes/) created by Michael Rose, and then extended to support the kinds of content that academics have: publications, talks, teaching, a portfolio, blog posts, and a dynamically-generated CV. You can fork [this repository](https://github.com/academicpages/academicpages.github.io) right now, modify the configuration and markdown files, add your own PDFs and other content, and have your own site for free, with no ads! An older version of this template powers my own personal website at [stuartgeiger.com](http://stuartgeiger.com), which uses [this Github repository](https://github.com/staeiou/staeiou.github.io). -->

Short Bio
======
I currently hold the position of Zhaohui Research Fellow with Special Appointment at Zhejiang University of Technology. I was a postdoctoral research fellow of Zhejiang University, working with Prof. [Chunhua Shen](https://cshen.github.io/) and Prof. [Hao Chen](https://stan-haochen.github.io/). In 2022, I received my Ph.D. degree of Beijing Institute of Technology (BIT), advised by Prof. [Yuwei Wu](https://sites.google.com/site/wuyuweibit/) and Prof. [Yunde Jia](https://scholar.google.com/citations?user=Sl6TV7gAAAAJ&hl=en). I also collaborate with Prof. [Qi Wu](http://www.qi-wu.me/) of the University of Adelaide. Prior to the Ph.D. study, I received the B.S. degree in computer science in 2016 from the BIT. My research area lies at the intersection of computer vision and natural language processing. 


<!-- Recent Publications
======
1. **Chenchen Jing**, Yukun Li, Hao Chen, and Chunhua Shen. Retrieval-augmented Primitive Representations for Compositional Zero-shot Learning. In Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI'24), 2024.
1. Muzhi Zhu, Hengtao Li, Hao Chen, Chengxiang Fan, Weian Mao, **Chenchen Jing**, Yifan Liu, Chunhua Shen. SegPrompt: Boosting Open-world Segmentation via Category-level Prompt Learning. In Proceedings of the IEEE Conference on Computer Vision (ICCV'23), 2023. [[pdf](https://arxiv.org/pdf/2308.06531)]
1. Chuanhao Li, Zhen Li, **Chenchen Jing**, Yunde Jia, Yuwei Wu. Exploring the Effect of Primitives for Compositional Generalization in Vision-and-Language. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'23), 2023. [[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Exploring_the_Effect_of_Primitives_for_Compositional_Generalization_in_Vision-and-Language_CVPR_2023_paper.pdf)] -->
<!-- 1. Qingsheng Wang, Lingqiao Liu, **Chenchen Jing**, Hao Chen, Guoqiang Liang, Peng Wang, Chunhua Shen. Learning Conditional Attributes for Compositional Zero-Shot Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'23), 2023. [[pdf](/files/papers/2023/CVPR-CANET.pdf)] -->


<!-- First-author Publications
======
1. **Chenchen Jing**, Yukun Li, Hao Chen, and Chunhua Shen. Retrieval-augmented Primitive Representations for Compositional Zero-shot Learning. In Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI'24), 2024.[[pdf](https://ojs.aaai.org/index.php/AAAI/article/view/28043/28096)]
1. **Chenchen Jing**,  Yunde Jia, Yuwei Wu, Xinyu Liu and Qi Wu. Maintaining Reasoning Consistency in Compositional Visual Question Answering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'22), 2022. [[pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jing_Maintaining_Reasoning_Consistency_in_Compositional_Visual_Question_Answering_CVPR_2022_paper.pdf)]
1. **Chenchen Jing**,  Yunde Jia, Yuwei Wu, Chuanhao Li and Qi Wu. Learning the Dynamics of Visual Relational Reasoning via Reinforced Path Routing. In Proceedings of the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI'22), 2022. [[pdf](https://ojs.aaai.org/index.php/AAAI/article/view/19997/19756)]
1. **Chenchen Jing**, Yuwei Wu, Mingtao Pei, Yao Hu, Yunde Jia and Qi Wu. Visual-Semantic Graph Matching for Visual Grounding. In Proceedings of the 28th ACM International Conference on Multimedia (MM ’20), 2020. [[pdf](/files/papers/2020/ACMMM_VSGM.pdf)]
1. **Chenchen Jing**, Yuwei Wu, Xiaoxun Zhang, Yunde Jia and Qi Wu. Overcoming Language Priors in VQA via Decomposed Linguistic Representations. In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI'20), 2020. [[pdf](https://ojs.aaai.org/index.php/AAAI/article/view/6776/6630)]
1. **Chenchen Jing**, Zhen Dong, Mingtao Pei and Yunde Jia. Heterogeneous Hashing Network for Face Retrieval across Image and Video Domains. IEEE Transactions on Multimedia (T-MM), 2019. [[pdf](/files/papers/2019/TMM_HHN.pdf)] -->
<!-- 1. **Chenchen Jing**, Zhen Dong, Mingtao Pei and Yunde Jia. Fusing Appearance Features and Correlation Features for Face Video Retrieval. Pacific Rim Conference on Multimedia (PCM), 2017. [[pdf](/files/papers/2017/PCM_Fusing.pdf)] -->


Selected Publications
======

1. Chuanhao Li, Zhen Li, **Chenchen Jing***, Xiaomeng Fan, Wenbo Ye, Yuwei Wu*, and Yunde Jia. Consistency of Compositional Generalization across Multiple Levels. In Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI), 2025.[[pdf](https://arxiv.org/pdf/2412.13636)]
1. Cong Chen, Mingyu Liu, **Chenchen Jing**, Yizhou Zhou, Fengyun Rao, Hao Chen, Bo Zhang, and Chunhua Shen. PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training. In Proceedings of the International Conference on Learning Representations (ICLR), 2025.[[pdf](https://arxiv.org/pdf/2503.06486)]
1. **Chenchen Jing**, Yukun Li, Hao Chen, and Chunhua Shen. Retrieval-augmented Primitive Representations for Compositional Zero-shot Learning. In Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI), 2024.[[pdf](https://ojs.aaai.org/index.php/AAAI/article/view/28043/28096)]
1. Chuanhao Li, Zhen Li, **Chenchen Jing***, Yuwei Wu*, Mingliang Zhai, and Yunde Jia. Compositional Substitutivity of Visual Reasoning for Visual Question Answering. The European Conference on Computer Vision(ECCV), 2024.[[pdf](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06434.pdf)]
1. Yang Liu, **Chenchen Jing**, Hengtao Li, Muzhi Zhu, Hao Chen*, Xinlong Wang, and Chunhua Shen.
A Simple Image Segmentation Framework via In-Context Examples. The Thirty-Eighth Annual Conference on Neural Information Processing Systems (NeurIPS), 2024.[[pdf](https://arxiv.org/pdf/2308.06531)]
1. Muzhi Zhu, Yang Liu, Zekai Luo, **Chenchen Jing**, Hao Chen*, Guangkai Xu, Xinlong Wang, and Chunhua Shen. Unleashing the Potential of the Diffusion Model in Few-shot Semantic Segmentation. The Thirty-Eighth Annual Conference on Neural Information Processing Systems (NeurIPS), 2024.[[pdf](https://proceedings.neurips.cc/paper_files/paper/2024/file/2cc0b08447bf9668db268e6c86364a6e-Paper-Conference.pdf)]
1. Chuanhao Li, Zhen Li, **Chenchen Jing**, Shuo Liu, Wenqi Shao, Yuwei Wu, Ping Luo, Yu Qiao, and Kaipeng Zhang. SearchLVLMs: A Plug-and-Play Framework for Augmenting Large Vision-Language Models by Searching Up-to-Date Internet Knowledge. The Thirty-Eighth Annual Conference on Neural Information Processing Systems (NeurIPS), 2024.[[pdf](https://openreview.net/pdf?id=leeosk2RAM)]
<!-- 1. Muzhi Zhu, Yang Liu, Zekai Luo, **Chenchen Jing**, Hao Chen*, Guangkai Xu, Xinlong Wang, and Chunhua Shen. Unleashing the Potential of the Diffusion Model in Few-shot Semantic Segmentation. The Thirty-Eighth Annual Conference on Neural Information Processing Systems (NeurIPS), 2024.[[pdf](https://proceedings.neurips.cc/paper_files/paper/2024/file/4b2a917e30e1bb1aff055b4d8c6c081c-Paper-Conference.pdf)] -->
1. Chuanhao Li, **Chenchen Jing**, Zhen Li, Mingliang Zhai, Yuwei Wu*, and Yunde Jia. In-Context Compositional Generalization for Large Vision-Language Models. The Conference on Empirical Methods in Natural Language Processing (EMNLP), 2024.[[pdf](https://arxiv.org/pdf/2308.06531)]
1. Muzhi Zhu, Hengtao Li, Hao Chen, Chengxiang Fan, Weian Mao, **Chenchen Jing**, Yifan Liu, and Chunhua Shen. SegPrompt: Boosting Open-world Segmentation via Category-level Prompt Learning. In Proceedings of the IEEE Conference on Computer Vision (ICCV'23), 2023. [[pdf](https://arxiv.org/pdf/2308.06531)]
1. Chuanhao Li, Zhen Li, **Chenchen Jing***, Yunde Jia, Yuwei Wu. Exploring the Effect of Primitives for Compositional Generalization in Vision-and-Language. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'23), 2023. [[pdf](/files/papers/2023/CVPR-Effect-of-Primitives.pdf)]
1. Qingsheng Wang, Lingqiao Liu, **Chenchen Jing**, Hao Chen, Guoqiang Liang, Peng Wang*, and Chunhua Shen. Learning Conditional Attributes for Compositional Zero-Shot Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'23), 2023. [[pdf](/files/papers/2023/CVPR-CANET.pdf)]
1. **Chenchen Jing**,  Yunde Jia, Yuwei Wu, Xinyu Liu and Qi Wu. Maintaining Reasoning Consistency in Compositional Visual Question Answering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR'22), 2022. [[pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Jing_Maintaining_Reasoning_Consistency_in_Compositional_Visual_Question_Answering_CVPR_2022_paper.pdf)]
1. **Chenchen Jing**,  Yunde Jia, Yuwei Wu, Chuanhao Li and Qi Wu. Learning the Dynamics of Visual Relational Reasoning via Reinforced Path Routing. In Proceedings of the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI'22), 2022. [[pdf](https://ojs.aaai.org/index.php/AAAI/article/view/19997/19756)]
1. Mingliang Zhai, Chuanhao Li,  **Chenchen Jing**, and Yuwei Wu. Synthesizing Counterfactual Samples for Overcoming Moment Biases in Temporal Video Grounding. In Proceedings of the Pattern Recognition and Computer Vision (PRCV'22), 2022. [[pdf](/files/papers/2022/PRCV_TVG.pdf)]
1. **Chenchen Jing**, Yuwei Wu, Mingtao Pei, Yao Hu, Yunde Jia and Qi Wu. Visual-Semantic Graph Matching for Visual Grounding. In Proceedings of the 28th ACM International Conference on Multimedia (MM ’20), 2020. [[pdf](/files/papers/2020/ACMMM_VSGM.pdf)]
1. **Chenchen Jing**, Yuwei Wu, Xiaoxun Zhang, Yunde Jia, and Qi Wu. Overcoming Language Priors in VQA via Decomposed Linguistic Representations. In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI'20), 2020. [[pdf](https://ojs.aaai.org/index.php/AAAI/article/view/6776/6630)]
1. **Chenchen Jing**, Zhen Dong, Mingtao Pei and Yunde Jia. Heterogeneous Hashing Network for Face Retrieval across Image and Video Domains. IEEE Transactions on Multimedia (T-MM), 2019. [[pdf](/files/papers/2019/TMM_HHN.pdf)]
1. Wei Jiang, Yuwei Wu*, **Chenchen Jing**, Tan Yu and Yunde Jia. Unsupervised Deep Quantization for Object Instance Search. Neurocomputing, 2019. [[pdf](/files/papers/2019/Neurocompution_UDQ.pdf)]
1. Zhen Dong, **Chenchen Jing**, Mingtao Pei* and Yunde Jia. Deep CNN based binary hash video representations for face retrieval. Pattern Recognition (PR), 2018. [[pdf](/files/papers/2018/PR_Hash_Video.pdf)]

<!-- Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header. 

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful.
 -->